{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('./wikipedia_ja_20240801')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset ã®ã†ã¡ï¼Œãƒ©ãƒ³ãƒ€ãƒ ã«ãª1000ä»¶ã‚’validationï¼Œåˆ¥ã®ãƒ©ãƒ³ãƒ€ãƒ ãª1000ä»¶ã‚’testï¼Œãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚’trainã«åˆ†å‰²\n",
    "dataset_dict = dataset.shuffle(seed=42).train_test_split(test_size=20, shuffle=True)\n",
    "train_dataset = dataset_dict['train']\n",
    "valid_and_test_dataset_dict = dataset_dict['test'].train_test_split(test_size=10, shuffle=True)\n",
    "valid_dataset = valid_and_test_dataset_dict['train']\n",
    "test_dataset = valid_and_test_dataset_dict['test']\n",
    "\n",
    "# æ”¹ã‚ã¦DatasetDictã‚’ä½œæˆ\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({'train': train_dataset, 'validation': valid_dataset, 'test': test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "model_name = \"ku-nlp/bart-base-japanese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'ï½œ âˆ’  ï½œ ï½œ âˆ’ ï½œ ï½œ ã€‚ â€ ã¯ ã€ æ—¥æœ¬ ã® åœ°å ã€‚ â€ ã“ã® é …ç›® ã¯ ã€ ã® ã€Œ ã€ ã‚’ ä½¿ç”¨ ã—ã¦ ã„ ã¾ã™ ã€‚ â€ ã€‚ ã“ã® ç¯€ ã® å‡ºå…¸ ï¼š ã€‚ ã“ã® é …ç›® ã§ ã¯ ã€ ï¼’ï¼ï¼ï¼ å¹´ ï¼“ æœˆ ï¼“ï¼‘ æ—¥ ç¾åœ¨ ã® ãƒ‡ãƒ¼ã‚¿ ã‚’ è¨˜è¼‰ ã™ã‚‹ ã€‚ ã“ã®'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer, max_new_tokens=60)\n",
    "generated = generator(dataset['train'][0]['text'])\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ï½œï¼‘ï¼™ï¼˜ï¼™ï¼ï¼™ï¼ï½œï½œï¼’ï¼‘ï½œï½œï¼ï½œï½œï¼’ï½œï½œï¼ï½œï½œï½œï½œï½œï½œï½œï½œ'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ï½œï¼‘ï¼™ï¼˜ï¼™ï¼ï¼™ï¼ï½œï½œï¼’ï¼‘ï½œï½œï¼ï½œï½œï¼’ï½œï½œï¼ï½œï½œï½œï½œï½œï½œï½œï½œ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[\"train\"][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ï¼¾ ï½‰ ï¼» ï½ƒï½ˆ ï½‰ ï½‹ï½™ ï½• ï¼½ ï½• ï¼ƒ ï½ˆ ï½ ï¼» ï½ƒï½ˆ ï½‰ ï½‹ï½™ ï½• ï¼½ ï½• ï¼¿ ï½‹ï½™ ï½• ï¼» ï½• ï½š ï½… ï¼½ ï½’ ï½ ï¼¿ ï½ ï½‰ ï¼½ ï½Š ï½• ï½• ï¼ƒ ï½‰ ï¼» ï½ƒï½ˆ ï½‰ ï¼¿ ï½š ï½… ï¼½ ï½’ ï½ ï¼¿ ï½ ï½‰ ï¼¿ ï½š ï½… ï¼½ ï½’ ï½ ï¼„</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"mbart_japanese_wikipedia\"\n",
    "output_dir = f\"exp/{exp_name}/results\"\n",
    "logging_dir = f\"exp/{exp_name}/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,             # æœ€å¤§3ã‚¨ãƒãƒƒã‚¯ã¨ã™ã‚‹\n",
    "    per_device_train_batch_size=8,  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    auto_find_batch_size=True,      # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã‚‹\n",
    "\n",
    "    weight_decay=0.01,              # é‡ã¿æ¸›è¡°\n",
    "    learning_rate=2e-5,             # å­¦ç¿’ç‡\n",
    "    warmup_steps=1000,              # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "\n",
    "    evaluation_strategy=\"steps\",    # è©•ä¾¡ã¯ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¡Œã†\n",
    "    eval_steps=500,                 # 500ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è©•ä¾¡ã‚’è¡Œã†\n",
    "    # metric_for_best_model=\"accuracy\", # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™\n",
    "    # greater_is_better=True,           # è©•ä¾¡æŒ‡æ¨™ãŒå¤§ãã„ã»ã©è‰¯ã„å ´åˆã¯True\n",
    "\n",
    "    output_dir=output_dir,          # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ\n",
    "    save_strategy=\"steps\",          # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¯ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«è¡Œã†\n",
    "    save_total_limit=3,             # ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ•°)\n",
    "\n",
    "    logging_dir=logging_dir,        # ãƒ­ã‚°ã®ä¿å­˜å…ˆ\n",
    "    logging_strategy=\"steps\",       # ãƒ­ã‚°ã®ä¿å­˜ã¯ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«è¡Œã†\n",
    "    logging_steps=500,              # 100ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹\n",
    "\n",
    "    load_best_model_at_end=True,    # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’æœ€å¾Œã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3, \n",
    "    early_stopping_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer #, DataCollatorWithPadding\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    # data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "/home/suzuki/.conda/envs/bert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167007' max='4012440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 167007/4012440 00:02 < 531:02:29, 2.01 it/s, Epoch 0.12/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m enable_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_training:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexp/mbart_japanese_wikipedia/results/checkpoint-167000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bert/lib/python3.10/site-packages/accelerate/utils/memory.py:157\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/.conda/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enable_training = True\n",
    "if enable_training:\n",
    "    trainer.train(resume_from_checkpoint=\"exp/mbart_japanese_wikipedia/results/checkpoint-167000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_model_loading = False\n",
    "output_dir = f\"exp/{exp_name}/results\"\n",
    "# model_path = f\"{output_dir}/checkpoint-58940\" # è‡ªåˆ†ã®é€²æ—çŠ¶æ³\n",
    "if enable_model_loading:\n",
    "    model = MBartForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'ï¼¾ ï½‹ ï½ ï¼» ï½‹ ï½• ï½“ ï½ ï½‰ ï½‚ ï½‰ ï½’ ï½• ï½ ï½ ï½ ï½… ï½Š ï½‰ ï½ ï½… ï¼® ï½” ï½ ï½‹ ï½ ï½‚ ï½• ï½“ï½ˆ ï½‰ ï½‹ ï½‰ ï½‡ ï½ ï¼½ ï½‰ ï½“ï½ˆ ï½ ï¼„'}]\n",
      "input: å›½éš›ãƒ“ãƒ«ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæ ªå¼ä¼šç¤¾\n",
      "target: ^ k o [ k u s a i b i r u m a n e j i m e N t o k a b u sh i k i g a ] i sh a $\n",
      "predicted: ï¼¾ ï½‹ ï½ ï¼» ï½‹ ï½• ï½“ ï½ ï½‰ ï½‚ ï½‰ ï½’ ï½• ï½ ï½ ï½ ï½… ï½Š ï½‰ ï½ ï½… ï¼® ï½” ï½ ï½‹ ï½ ï½‚ ï½• ï½“ï½ˆ ï½‰ ï½‹ ï½‰ ï½‡ ï½ ï¼½ ï½‰ ï½“ï½ˆ ï½ ï¼„\n"
     ]
    }
   ],
   "source": [
    "split = 'validation'\n",
    "i = 1\n",
    "predicted = generator(dataset[split][i][\"text\"])\n",
    "print(predicted)\n",
    "print(f\"input: {dataset[split][i]['text']}\")\n",
    "print(f\"target: {dataset[split][i]['phones']}\")\n",
    "print(f\"predicted: {predicted[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ï¼¾ ï½“ï½ˆ ï½‰ ï¼» ï½’ ï½ ï¼½ ï½ ï½ ï½‰ ï¼ƒ ï½ˆ ï½‰ ï¼» ï½” ï½ ï½ ï½‰ ï¼ƒ ï½ ï½‰ ï¼» ï½ƒï½ˆ ï½‰ ï½ ï¼ƒ ï½‹ ï½‰ ï¼» ï½‰ ï½” ï½… ï¼ƒ ï½• ï¼» ï½ ï½ ï¼½ ï½“ï½ˆ ï½‰ ï½” ï½ ï¼„'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"çŸ¥ã‚‰ãªã„äººã«é“ã‚’èã„ã¦ã¿ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ï¼¾ ï½“ ï½… ï¼½ ï¼® ï¼ƒ ï½ ï½‰ ï¼» ï½ˆï½™ ï½ ï½‹ ï½• ï¼½ ï½ ï½ ï¼® ï¼ƒ ï½“ï½ˆ ï½‰ ï¼» ï½ƒï½Œ ï½“ ï½… ï¼® ï¼½ ï½‡ ï½ ï¼ƒ ï½ˆ ï½‰ ï¼» ï½’ ï½ ï½ ï½ ï¼½ ï½ƒï½Œ ï½” ï½ ï¼„'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"åƒäºŒç™¾ä¸‡ä¸ƒåƒäº”ç™¾åä¸ƒå††\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ï¼¾ ï½‹ ï½ ï¼» ï¼® ï½„ ï½… ï¼® ï½… ï½… ï½ ï½… ï¼® ï½“ï½ˆ ï½‰ ï½š ï½ ï½‰ ï¼½ ï½ˆ ï½ ï½ ï¼„'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"å¢¾ç”°æ°¸å¹´ç§è²¡æ³•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ï¼¾ ï½ˆ ï½ ï¼» ï½“ï½ˆ ï½‰ ï½ ï½ ï¼½ ï½ˆ ï½ ï½“ï½ˆ ï½‰ ï½„ ï½… ï¼ƒ ï½ˆ ï½ ï¼½ ï½“ï½ˆ ï½‰ ï¼ƒ ï½ ï½ ï¼ƒ ï½” ï½ ï¼» ï¼® ï½ ï¼ƒ ï½ ï½ ï¼½ ï½ƒï½Œ ï½” ï½… ï¼„'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"æ©‹ã®ç«¯ã§ç®¸ã®ç«¯ã‚’æŒã£ã¦èµ°ã£ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ï¼¾ ï½ ï½ ï¼» ï½ƒï½Œ ï½‹ ï½… ï½… ï½ ï½ ï¼½ ï¼® ï½“ ï½• ï½” ï½ ï½ ï¼„'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"ãƒã‚±ãƒƒãƒˆãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
